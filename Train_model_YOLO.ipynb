{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je1HKIZP0DXe",
        "outputId": "a53dc030-f683-4966-e31b-5c55e8718846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'leaf_disease'...\n",
            "remote: Enumerating objects: 1730, done.\u001b[K\n",
            "remote: Counting objects: 100% (554/554), done.\u001b[K\n",
            "remote: Compressing objects: 100% (410/410), done.\u001b[K\n",
            "remote: Total 1730 (delta 189), reused 318 (delta 138), pack-reused 1176 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1730/1730), 2.69 MiB | 4.87 MiB/s, done.\n",
            "Resolving deltas: 100% (627/627), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://mcflinta: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@github.com/mcflinta/leaf_disease.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cài thư viện ultralytics"
      ],
      "metadata": {
        "id": "ncoxQRyy3iw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd leaf_disease/ultralytics-main/\n",
        "!pip install -e .\n",
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmb9wwW10vI3",
        "outputId": "4e0a178c-1bc7-43f6-ac29-7931c560761d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/leaf_disease/ultralytics-main\n",
            "Obtaining file:///content/leaf_disease/ultralytics-main\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.31) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics==8.3.31)\n",
            "  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.31) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.3.31) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.3.31) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.31) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.31) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.31) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.31) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.31) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.31) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.31) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.31) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.31) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.31) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.31) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.31) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.31) (3.0.2)\n",
            "Downloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: ultralytics\n",
            "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ultralytics: filename=ultralytics-8.3.31-0.editable-py3-none-any.whl size=22702 sha256=d1fb2578bd6db64fa4c4dd01855c85692098688f35d00032e93000caacb29ca9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6vf047io/wheels/8d/d0/d9/662534528d8b9b1ff90c63efc8b64dbcda158a6faa357babc4\n",
            "Successfully built ultralytics\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.31 ultralytics-thop-2.0.11\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tải dataset và giải nén"
      ],
      "metadata": {
        "id": "VhOrcq3V3pCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import sys\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def download(name = 'errors'):\n",
        "        if(name == 'errors'):\n",
        "            return\n",
        "        else:\n",
        "            r = requests.get(\"http://149.28.146.58:3000/datasets/link\")\n",
        "            data = r.json()\n",
        "            for d in data:\n",
        "                if(d['name'] == name):\n",
        "                    link = d['link']\n",
        "            url =  link\n",
        "            local_filename = url.split('/')[-1]\n",
        "            print('Starting Download, Please wait.....')\n",
        "            chunk_size = 4096\n",
        "            r = requests.get(url, stream=True)\n",
        "            with open(local_filename, 'wb') as f:\n",
        "                print(\"Downloading %s\" % local_filename)\n",
        "                response = requests.get(url, stream=True)\n",
        "                total_length = response.headers.get('content-length')\n",
        "                if total_length is None: # no content length header\n",
        "                  f.write(response.content)\n",
        "                else:\n",
        "                    dl = 0\n",
        "                    total_length = int(total_length)\n",
        "                    for data in response.iter_content(int(total_length / 100)):\n",
        "                        dl += len(data)\n",
        "                        f.write(data)\n",
        "                        done = int(50 * dl / total_length)\n",
        "                        sys.stdout.write(\"\\r[%s%s]\" % ('=' * done, ' ' * (50-done))  )\n",
        "                        sys.stdout.flush()\n",
        "\n",
        "            print('\\nDownload '+ name +' complete.')\n",
        "            with ZipFile(local_filename, 'r') as zip:\n",
        "                print('Extracting all the files now...')\n",
        "                zip.extractall()\n",
        "            # train = pd.read_csv('/content/iec-models/model_data/train.csv')\n",
        "            return local_filename"
      ],
      "metadata": {
        "id": "BTKUJ8E-1E1J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"Small-Banana-Dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "TiUdMTkY1l3r",
        "outputId": "58cafe40-88a6-43ca-e34d-f13af35e2c7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Download, Please wait.....\n",
            "Downloading small-banana-dataset.zip\n",
            "[==================================================]\n",
            "Download Small-Banana-Dataset complete.\n",
            "Extracting all the files now...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'small-banana-dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xử lý dữ liệu"
      ],
      "metadata": {
        "id": "JngMjOtPCnxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "data = {\n",
        "    'train': 'images/train/',\n",
        "    'val': 'images/val/',\n",
        "    'nc': 2,\n",
        "    'names': {\n",
        "        0: 'early_sigatoka',\n",
        "        1: 'late_sigatoka'\n",
        "    },\n",
        "}\n",
        "\n",
        "# Path to save the YAML file\n",
        "yaml_file = 'data.yaml'\n",
        "\n",
        "# Writing data to YAML file\n",
        "with open(yaml_file, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(f\"YAML file '{yaml_file}' created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuatXuCp_OlD",
        "outputId": "a65cea5b-6e5c-458b-802a-6b8061ea511e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML file 'data.yaml' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def get_filename_without_extension(file_path):\n",
        "        list_file = os.listdir(file_path)\n",
        "        result = []\n",
        "        for item_file in list_file:\n",
        "            filename = os.path.basename(item_file)\n",
        "            result.append(os.path.splitext(filename)[0])\n",
        "        return result"
      ],
      "metadata": {
        "id": "UA2eZPaH_kuO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chia 8/2 từ Small-Banana-Dataset:\n",
        "* 8: Data cho Banana-Dataset-TrainVal\n",
        "* 2: Data cho Banana-Dataset-Test"
      ],
      "metadata": {
        "id": "O219tEB3Ec6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import yaml\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "dataset_path = Path('small-banana-dataset/')\n",
        "labels = sorted(dataset_path.rglob('*labels/*.txt'))\n",
        "yaml_file = 'data.yaml'  # your data YAML with data directories and names dictionary\n",
        "with open(yaml_file, 'r', encoding=\"utf8\") as y:\n",
        "    classes = yaml.safe_load(y)['names']\n",
        "cls_idx = sorted(classes.keys())\n",
        "indx = [l.stem for l in labels]\n",
        "\n",
        "\n",
        "labels_df = pd.DataFrame([], columns=cls_idx, index=indx)\n",
        "for label in labels:\n",
        "    lbl_counter = Counter()\n",
        "    with open(label, 'r') as lf:\n",
        "        lines = lf.readlines()\n",
        "        for l in lines:\n",
        "            lbl_counter[int(l.split(' ')[0])] += 1\n",
        "            labels_df.loc[label.stem] = lbl_counter\n",
        "\n",
        "labels_df = labels_df.fillna(0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq-Vz1rG_ud6",
        "outputId": "c30bda77-a94e-4a76-95dd-37db15d23b45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-caa1009d6688>:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  labels_df = labels_df.fillna(0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_label_1 = labels_df[0].sum()\n",
        "total_label_2 = labels_df[1].sum()\n",
        "print(f'Early_sigatoka: {total_label_1}\\nLate_sigatoka: {total_label_2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2uDQK4n_7-G",
        "outputId": "ea277425-6edf-4c30-826e-a45dd460b701"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early_sigatoka: 2526.0\n",
            "Late_sigatoka: 339.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "labels_df = labels_df.fillna(0.0) # replace `nan` values with `0.0`\n",
        "ksplit = 5\n",
        "skf = StratifiedKFold(n_splits=ksplit, shuffle=True, random_state=20)"
      ],
      "metadata": {
        "id": "WIqkQj1nAUhG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfolds = list(skf.split(labels_df, labels_df.idxmax(axis=1)))\n",
        "folds = [f'split_{n}' for n in range(1, ksplit + 1)]\n",
        "folds_df = pd.DataFrame(index=indx, columns=folds)\n",
        "# print(len(labels_df.idxmax(axis=1)))\n",
        "for idx, (train, val) in enumerate(kfolds, start=1):\n",
        "    folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'Banana-Dataset-TrainVal'\n",
        "    folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'Banana-Dataset-Test'\n",
        "\n",
        "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkIhuRcsAYFf",
        "outputId": "9c4feae5-5b28-45f4-dfc5-4785e81df017"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-24b59b761ea5>:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'Banana-Dataset-TrainVal'\n",
            "<ipython-input-10-24b59b761ea5>:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'Banana-Dataset-Test'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
        "    train_totals = labels_df.iloc[train_indices].sum()\n",
        "    val_totals = labels_df.iloc[val_indices].sum()\n",
        "\n",
        "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
        "    ratio = val_totals / (train_totals + 1E-7)\n",
        "    fold_lbl_distrb.loc[f'split_{n}'] = ratio"
      ],
      "metadata": {
        "id": "d0n8kZtnAafQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supported_extensions = ['.JPG', '.jpeg', '.png', '.txt']\n",
        "# Initialize an empty list to store image file paths\n",
        "images = []\n",
        "\n",
        "yolo_path = \"/content/\"\n",
        "os.makedirs(yolo_path, exist_ok=True)\n",
        "# Loop through supported extensions and gather image files\n",
        "dataset_path_1 = Path('small-banana-dataset/')\n",
        "for ext in supported_extensions:\n",
        "    images.extend(sorted((dataset_path_1 / 'labels').rglob(f\"*{ext}\")))\n",
        "\n",
        "# Create the necessary directories and dataset YAML files (unchanged)\n",
        "save_path = Path(yolo_path)\n",
        "save_path.mkdir(parents=True, exist_ok=True)\n",
        "ds_yamls = []\n",
        "\n",
        "# for split in folds_df.columns:\n",
        "#     # Create directories\n",
        "#     split_dir = save_path / split\n",
        "#     split_dir.mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'Banana-Dataset-TrainVal' / 'images').mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'Banana-Dataset-TrainVal' / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'Banana-Dataset-Test' / 'images').mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'Banana-Dataset-Test' / 'labels').mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Q9ZDCcjyAdRu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [inner.with_suffix(\".JPG\") for inner in images]\n",
        "images = [Path('small-banana-dataset/images') / inner.name for inner in images]"
      ],
      "metadata": {
        "id": "w8bmQzIMBDQy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in zip(images, labels):\n",
        "    image_name = image.stem  # Tên của tệp hình ảnh (không bao gồm phần mở rộng)\n",
        "    split = folds_df.columns[0]\n",
        "    k_split = folds_df.loc[image_name, split]\n",
        "    # Đảm bảo split và k_split không rỗng\n",
        "    if pd.notna(k_split):\n",
        "        # Thư mục đích\n",
        "        img_to_path = save_path / k_split / 'images'\n",
        "        lbl_to_path = save_path / k_split / 'labels'\n",
        "        # Tạo thư mục đích nếu chx`ưa tồn tại\n",
        "        img_to_path.mkdir(parents=True, exist_ok=True)\n",
        "        lbl_to_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Sao chép tệp hình ảnh và nhãn vào thư mục mới\n",
        "        shutil.copy(image, img_to_path / image.name)\n",
        "        shutil.copy(label, lbl_to_path / label.name)"
      ],
      "metadata": {
        "id": "SWtfqSPPA-QA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chia 8/2 từ Banana-Dataset-TrainVal:\n",
        "* 8: Data cho train\n",
        "* 2: Data cho val"
      ],
      "metadata": {
        "id": "BGFFGpIQGP4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import yaml\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "dataset_path = Path('Banana-Dataset-TrainVal/')\n",
        "labels = sorted(dataset_path.rglob('*labels/*.txt'))\n",
        "yaml_file = 'data.yaml'  # your data YAML with data directories and names dictionary\n",
        "with open(yaml_file, 'r', encoding=\"utf8\") as y:\n",
        "    classes = yaml.safe_load(y)['names']\n",
        "cls_idx = sorted(classes.keys())\n",
        "indx = [l.stem for l in labels]\n",
        "\n",
        "\n",
        "labels_df = pd.DataFrame([], columns=cls_idx, index=indx)\n",
        "for label in labels:\n",
        "    lbl_counter = Counter()\n",
        "    with open(label, 'r') as lf:\n",
        "        lines = lf.readlines()\n",
        "        for l in lines:\n",
        "            lbl_counter[int(l.split(' ')[0])] += 1\n",
        "            labels_df.loc[label.stem] = lbl_counter\n",
        "\n",
        "labels_df = labels_df.fillna(0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfiA8bPoGO6O",
        "outputId": "9c686589-ecfe-4346-c6a9-bdec9f5dc5e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-befe45e90764>:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  labels_df = labels_df.fillna(0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_label_1 = labels_df[0].sum()\n",
        "total_label_2 = labels_df[1].sum()\n",
        "print(f'Early_sigatoka: {total_label_1}\\nLate_sigatoka: {total_label_2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDUVV4GEGpn6",
        "outputId": "1d7994c7-3888-421e-a70a-08c5d9a9b447"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early_sigatoka: 1969.0\n",
            "Late_sigatoka: 267.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "labels_df = labels_df.fillna(0.0) # replace `nan` values with `0.0`\n",
        "ksplit = 5\n",
        "skf = StratifiedKFold(n_splits=ksplit, shuffle=True, random_state=20)"
      ],
      "metadata": {
        "id": "UPxq5oRiH1MS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfolds = list(skf.split(labels_df, labels_df.idxmax(axis=1)))\n",
        "folds = [f'split_{n}' for n in range(1, ksplit + 1)]\n",
        "folds_df = pd.DataFrame(index=indx, columns=folds)\n",
        "# print(len(labels_df.idxmax(axis=1)))\n",
        "for idx, (train, val) in enumerate(kfolds, start=1):\n",
        "    folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'train'\n",
        "    folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'val'\n",
        "\n",
        "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDYCtmhbH7s9",
        "outputId": "06b1207a-7c1f-4ef8-9465-6d1b1bca53c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-08bed0d63256>:6: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'train'\n",
            "<ipython-input-18-08bed0d63256>:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
            "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
            "A typical example is when you are setting values in a column of a DataFrame, like:\n",
            "\n",
            "df[\"col\"][row_indexer] = value\n",
            "\n",
            "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "  folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'val'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
        "    train_totals = labels_df.iloc[train_indices].sum()\n",
        "    val_totals = labels_df.iloc[val_indices].sum()\n",
        "\n",
        "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
        "    ratio = val_totals / (train_totals + 1E-7)\n",
        "    fold_lbl_distrb.loc[f'split_{n}'] = ratio"
      ],
      "metadata": {
        "id": "HlN6Mf60H_s4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supported_extensions = ['.JPG', '.jpeg', '.png', '.txt']\n",
        "# Initialize an empty list to store image file paths\n",
        "images = []\n",
        "\n",
        "yolo_path = \"/content/Banana-Dataset/\"\n",
        "os.makedirs(yolo_path, exist_ok=True)\n",
        "# Loop through supported extensions and gather image files\n",
        "dataset_path_1 = Path('Banana-Dataset-TrainVal/')\n",
        "for ext in supported_extensions:\n",
        "    images.extend(sorted((dataset_path_1 / 'labels').rglob(f\"*{ext}\")))\n",
        "\n",
        "# Create the necessary directories and dataset YAML files (unchanged)\n",
        "save_path = Path(yolo_path)\n",
        "save_path.mkdir(parents=True, exist_ok=True)\n",
        "ds_yamls = []\n",
        "\n",
        "# for split in folds_df.columns:\n",
        "#     # Create directories\n",
        "#     split_dir = save_path / split\n",
        "#     split_dir.mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'train' / 'images').mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'train' / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'val' / 'images').mkdir(parents=True, exist_ok=True)\n",
        "(save_path / 'val' / 'labels').mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Xof7WAeZGsEb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [inner.with_suffix(\".JPG\") for inner in images]\n",
        "images = [Path('Banana-Dataset-TrainVal/images') / inner.name for inner in images]"
      ],
      "metadata": {
        "id": "OtHEdbq_HW4T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, label in zip(images, labels):\n",
        "    image_name = image.stem  # Tên của tệp hình ảnh (không bao gồm phần mở rộng)\n",
        "    split = folds_df.columns[0]\n",
        "    k_split = folds_df.loc[image_name, split]\n",
        "    # Đảm bảo split và k_split không rỗng\n",
        "    if pd.notna(k_split):\n",
        "        # Thư mục đích\n",
        "        img_to_path = save_path / k_split / 'images'\n",
        "        lbl_to_path = save_path / k_split / 'labels'\n",
        "        # Tạo thư mục đích nếu chx`ưa tồn tại\n",
        "        img_to_path.mkdir(parents=True, exist_ok=True)\n",
        "        lbl_to_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Sao chép tệp hình ảnh và nhãn vào thư mục mới\n",
        "        shutil.copy(image, img_to_path / image.name)\n",
        "        shutil.copy(label, lbl_to_path / label.name)"
      ],
      "metadata": {
        "id": "4tU4AW4_HfSD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check amount annotations"
      ],
      "metadata": {
        "id": "ElmYW5DLBdn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "# Đường dẫn tới file label\n",
        "dataset_path1 = Path('Banana-Dataset/train/')\n",
        "labels = sorted(dataset_path1.rglob('*labels/*.txt'))\n",
        "# label_train = sorted(Path(\"/labels\").glob(\"*.txt\"))\n",
        "# label_train = sorted(Path(\"temp_merge/labels/\").glob(\"*.txt\"))\n"
      ],
      "metadata": {
        "id": "oS92Li5xBP8c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indx_1 = [l.stem for l in labels]\n",
        "labels_df_1 = pd.DataFrame([], columns=cls_idx, index=indx_1)"
      ],
      "metadata": {
        "id": "UCk_-RHIB5D_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in labels:\n",
        "  lbl_counter = Counter()\n",
        "  with open(label, 'r') as lf:\n",
        "    lines = lf.readlines()\n",
        "  for l in lines:\n",
        "    lbl_counter[int(l.split(' ')[0])] += 1\n",
        "  labels_df_1.loc[label.stem] = lbl_counter\n",
        "\n",
        "labels_df_1 = labels_df_1.fillna(0.0)\n",
        "# label.stem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-4_nU_GCHfr",
        "outputId": "da23c6d8-55fc-4c1b-d013-264742d37b7c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-f7d67473684f>:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  labels_df_1 = labels_df_1.fillna(0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_label_train_1 = labels_df_1[0].sum()\n",
        "total_label_train_2 = labels_df_1[1].sum()\n",
        "total_label_train_1, total_label_train_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2GmG3bvCKi-",
        "outputId": "49347946-39cf-4140-9084-ec25bbc88664"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1630.0, 232.0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tạo file config"
      ],
      "metadata": {
        "id": "mp1Q7F_p3v-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'train': '/content/Banana-Dataset/train/',\n",
        "    'val': '/content/Banana-Dataset/val/',\n",
        "    'nc': 2,\n",
        "    'names': ['early_sigatoka', 'late_sigatoka']\n",
        "}\n",
        "\n",
        "# Tạo file YAML\n",
        "with open('config.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(\"Tệp YAML đã được tạo thành công.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKp3hhqs2X0k",
        "outputId": "79275c25-6a62-4145-ec16-93b41ecbce51"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tệp YAML đã được tạo thành công.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "E8N9QbPBCuW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo train model=yolo11.yaml data=config.yaml epochs=10 imgsz=1024 batch=32 name=YOLOv11n project=YOLO device=0 close_mosaic=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz7WLflY2MDb",
        "outputId": "9e4830d8-2275-4540-9feb-479747783cdf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
            "Ultralytics 8.3.31 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11.yaml, data=config.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=1024, save=True, save_period=-1, cache=False, device=0, workers=8, project=YOLO, name=YOLOv11n, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=YOLO/YOLOv11n\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 22.8MB/s]\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "WARNING ⚠️ no model scale passed. Assuming scale='n'.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "YOLO11 summary: 319 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir YOLO/YOLOv11n', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n",
            "100% 5.35M/5.35M [00:00<00:00, 84.8MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Banana-Dataset/train/labels... 206 images, 0 backgrounds, 0 corrupt: 100% 206/206 [00:00<00:00, 1979.71it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Banana-Dataset/train/images/DJI_20240112094955_0603_D.JPG: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Banana-Dataset/train/images/DJI_20240112095923_0415_D.JPG: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/Banana-Dataset/train/images/DJI_20240112100058_0551_D.JPG: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Banana-Dataset/train/labels.cache\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Banana-Dataset/val/labels... 52 images, 0 backgrounds, 0 corrupt: 100% 52/52 [00:00<00:00, 1390.46it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /content/Banana-Dataset/val/images/DJI_20240112095022_0641_D.JPG: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Banana-Dataset/val/labels.cache\n",
            "Plotting labels to YOLO/YOLOv11n/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 1024 train, 1024 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mYOLO/YOLOv11n\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10        13G      6.341      160.3      4.323        104       1024: 100% 7/7 [00:15<00:00,  2.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.86s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10      12.1G      6.838      243.8      4.271        105       1024: 100% 7/7 [00:05<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.99s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      11.9G      5.868      158.7      3.682         96       1024: 100% 7/7 [00:05<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.59s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10        12G      6.393      156.2      3.989        123       1024: 100% 7/7 [00:06<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.79s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10        12G      5.602      59.96      3.462        116       1024: 100% 7/7 [00:05<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.67s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10      11.9G      4.848       34.5      2.986         98       1024: 100% 7/7 [00:06<00:00,  1.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.81s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      12.4G      4.136      19.79      2.354        114       1024: 100% 7/7 [00:05<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.57s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10        12G      3.778      13.93      2.066         94       1024: 100% 7/7 [00:05<00:00,  1.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.61s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10      11.9G      3.745      10.84      2.175         73       1024: 100% 7/7 [00:06<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:02<00:00,  2.66s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10      12.1G      3.731       10.2      1.905         76       1024: 100% 7/7 [00:05<00:00,  1.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.70s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "\n",
            "10 epochs completed in 0.033 hours.\n",
            "Optimizer stripped from YOLO/YOLOv11n/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from YOLO/YOLOv11n/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating YOLO/YOLOv11n/weights/best.pt...\n",
            "WARNING ⚠️ validating an untrained model YAML will result in 0 mAP.\n",
            "Ultralytics 8.3.31 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11 summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.44s/it]\n",
            "                   all         52        373          0          0          0          0\n",
            "Speed: 0.4ms preprocess, 6.4ms inference, 0.0ms loss, 14.8ms postprocess per image\n",
            "Results saved to \u001b[1mYOLO/YOLOv11n\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "data = {\n",
        "    'train': '/content/Banana-Dataset-Test/',\n",
        "    'val': '/content/Banana-Dataset-Test/',\n",
        "    'nc': 2,\n",
        "    'names': ['early_sigatoka', 'late_sigatoka']\n",
        "}\n",
        "\n",
        "# Tạo file YAML\n",
        "with open('config_test.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(\"Tệp YAML đã được tạo thành công.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmEqSMF-IPqN",
        "outputId": "f0a2a7af-1f19-43b1-92f3-e865cbe32c52"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tệp YAML đã được tạo thành công.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Val model"
      ],
      "metadata": {
        "id": "aHZ_TdOOC-rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val model=/content/YOLO/YOLOv11n/weights/best.pt data=config_test.yaml imgsz=1024 batch=16 name=YOLOv11n-test project=YOLO device=0"
      ],
      "metadata": {
        "id": "DCISbE5o6Znq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d57cb4c-682c-461d-e434-be652b40bb0e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.31 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLO11 summary (fused): 238 layers, 2,582,542 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Banana-Dataset-Test/labels... 65 images, 0 backgrounds, 0 corrupt: 100% 65/65 [00:00<00:00, 275.47it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Banana-Dataset-Test/labels.cache\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 5/5 [00:05<00:00,  1.02s/it]\n",
            "                   all         65        629          0          0          0          0\n",
            "Speed: 0.6ms preprocess, 28.0ms inference, 0.0ms loss, 32.2ms postprocess per image\n",
            "Results saved to \u001b[1mYOLO/YOLOv11n-test\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict Images"
      ],
      "metadata": {
        "id": "FAoLi9thD3Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wy1zVIGXD1kM"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}